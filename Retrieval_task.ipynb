{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import xlsxwriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excel_write_all(name, fun, desc, n):\n",
    "    with xlsxwriter.Workbook(name) as workbook:\n",
    "        worksheet = workbook.add_worksheet()\n",
    "\n",
    "        for row_num, data in enumerate(fun):       \n",
    "            worksheet.write(n + row_num, 0, data)\n",
    "        \n",
    "        for row_num, data in enumerate(desc):        \n",
    "            worksheet.write(n + row_num, 1, data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excel_write(name, fun, desc):\n",
    "    with xlsxwriter.Workbook(name) as workbook:\n",
    "        worksheet = workbook.add_worksheet()\n",
    "\n",
    "        for row_num, data in enumerate(fun):       \n",
    "            worksheet.write(row_num, 0, data)\n",
    "        \n",
    "        for row_num, data in enumerate(desc):        \n",
    "            worksheet.write(row_num, 1, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To scrap functions when data is present in tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Links = ['https://numpy.org/doc/stable/reference/arrays.scalars.html'] # list of links to retrieve data from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 32 # excel files are numbered, n is the starting file number\n",
    "for html_doc in Links:\n",
    "    doc = requests.get(html_doc)\n",
    "    src = doc.content;\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "    fun = []\n",
    "    desc = []\n",
    "    s = soup.find_all(class_={'row-even', 'row-odd'})\n",
    "    for i in s:\n",
    "        try:\n",
    "            q = (i.find('span').string)\n",
    "            st = ''\n",
    "            for d in i.find_all('td')[1].find('p').children:\n",
    "                st += d.string\n",
    "            fun.append(q)\n",
    "            desc.append(st)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    name = str(n)+'.xlsx'\n",
    "    excel_write(name, fun, desc)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To scrap functions when data is present in <p> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.tensorflow.org/api_docs/python/tf/sets\n"
     ]
    }
   ],
   "source": [
    "# shortened urls, we complete it by prepending fixed url before each of these\n",
    "Links = ['saved','sets','signal','sparse','strings','summary','sysconfig','test','tpu','train','types','version','xla']\n",
    "print('https://www.tensorflow.org/api_docs/python/tf/'+Links[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.xlsx\n",
      "[]\n",
      "[]\n",
      "201.xlsx\n",
      "['difference(...)', 'intersection(...)', 'size(...)', 'union(...)']\n",
      "[' Compute set difference of elements in last dimension of a and b.', ' Compute set intersection of elements in last dimension of a and b.', ' Compute number of unique elements along last dimension of a.', ' Compute set union of elements in last dimension of a and b.']\n",
      "202.xlsx\n",
      "['dct(...)', 'fft(...)', 'fft2d(...)', 'fft3d(...)', 'fftshift(...)', 'frame(...)', 'hamming_window(...)', 'hann_window(...)', 'idct(...)', 'ifft(...)', 'ifft2d(...)', 'ifft3d(...)', 'ifftshift(...)', 'inverse_mdct(...)', 'inverse_stft(...)', 'inverse_stft_window_fn(...)', 'irfft(...)', 'irfft2d(...)', 'irfft3d(...)', 'kaiser_bessel_derived_window(...)', 'kaiser_window(...)', 'linear_to_mel_weight_matrix(...)', 'mdct(...)', 'mfccs_from_log_mel_spectrograms(...)', 'overlap_and_add(...)', 'rfft(...)', 'rfft2d(...)', 'rfft3d(...)', 'stft(...)', 'vorbis_window(...)']\n",
      "[' Computes the 1D [Discrete Cosine Transform (DCT)][dct] of input.', ' Fast Fourier transform.', ' 2D fast Fourier transform.', ' 3D fast Fourier transform.', ' Shift the zero-frequency component to the center of the spectrum.', \" Expands signal's axis dimension into frames of frame_length.\", ' Generate a Hamming window.', ' Generate a Hann window.', ' Computes the 1D [Inverse Discrete Cosine Transform (DCT)][idct] of input.', ' Inverse fast Fourier transform.', ' Inverse 2D fast Fourier transform.', ' Inverse 3D fast Fourier transform.', ' The inverse of fftshift.', ' Computes the inverse modified DCT of mdcts.', ' Computes the inverse Short-time Fourier Transform of stfts.', ' Generates a window function that can be used in inverse_stft.', ' Inverse real-valued fast Fourier transform.', ' Inverse 2D real-valued fast Fourier transform.', ' Inverse 3D real-valued fast Fourier transform.', ' Generate a [Kaiser Bessel derived window][kbd].', ' Generate a [Kaiser window][kaiser].', ' Returns a matrix to warp linear scale spectrograms to the mel scale.', ' Computes the [Modified Discrete Cosine Transform][mdct] of signals.', ' Computes MFCCs of log_mel_spectrograms.', ' Reconstructs a signal from a framed representation.', ' Real-valued fast Fourier transform.', ' 2D real-valued fast Fourier transform.', ' 3D real-valued fast Fourier transform.', ' Computes the Short-time Fourier Transform of signals.', ' Generate a [Vorbis power complementary window][vorbis].']\n",
      "203.xlsx\n",
      "['class SparseTensor', 'add(...)', 'bincount(...)', 'concat(...)', 'cross(...)', 'cross_hashed(...)', 'expand_dims(...)', 'eye(...)', 'fill_empty_rows(...)', 'from_dense(...)', 'map_values(...)', 'mask(...)', 'maximum(...)', 'minimum(...)', 'reduce_max(...)', 'reduce_max(...)', 'reduce_sum(...)', 'reduce_sum(...)', 'reorder(...)', 'reset_shape(...)', 'reshape(...)', 'retain(...)', 'segment_mean(...)', 'segment_sqrt_n(...)', 'segment_sum(...)', 'slice(...)', 'softmax(...)', 'sparse_dense_matmul(...)', 'split(...)', 'to_dense(...)', 'to_indicator(...)', 'transpose(...)']\n",
      "[' Represents a sparse tensor.', ' Adds two tensors, at least one of each is a SparseTensor.', ' Count the number of times an integer value appears in a tensor.', ' Concatenates a list of SparseTensor along the specified dimension. (deprecated arguments)', ' Generates sparse cross from a list of sparse and dense tensors.', ' Generates hashed sparse cross from a list of sparse and dense tensors.', ' Returns a tensor with an length 1 axis inserted at index axis.', ' Creates a two-dimensional sparse tensor with ones along the diagonal.', ' Fills empty rows in the input 2-D SparseTensor with a default value.', ' Converts a dense tensor into a sparse tensor.', ' Applies op to the .values tensor of one or more SparseTensors.', ' Masks elements of IndexedSlices.', ' Returns the element-wise max of two SparseTensors.', ' Returns the element-wise min of two SparseTensors.', ' Computes tf.sparse.maximum of elements across dimensions of a SparseTensor.', ' Computes tf.sparse.maximum of elements across dimensions of a SparseTensor.', ' Computes tf.sparse.add of elements across dimensions of a SparseTensor.', ' Computes tf.sparse.add of elements across dimensions of a SparseTensor.', ' Reorders a SparseTensor into the canonical, row-major ordering.', ' Resets the shape of a SparseTensor with indices and values unchanged.', ' Reshapes a SparseTensor to represent values in a new dense shape.', ' Retains specified non-empty values within a SparseTensor.', ' Computes the mean along sparse segments of a tensor.', ' Computes the sum along sparse segments of a tensor divided by the sqrt(N).', ' Computes the sum along sparse segments of a tensor.', ' Slice a SparseTensor based on the start and size.', ' Applies softmax to a batched N-D SparseTensor.', ' Multiply SparseTensor (or dense Matrix) (of rank 2) \"A\" by dense matrix', ' Split a SparseTensor into num_split tensors along axis.', ' Converts a SparseTensor into a dense tensor.', ' Converts a SparseTensor of ids into a dense bool indicator tensor.', ' Transposes a SparseTensor']\n",
      "204.xlsx\n",
      "['as_string(...)', 'bytes_split(...)', 'format(...)', 'join(...)', 'length(...)', 'lower(...)', 'ngrams(...)', 'reduce_join(...)', 'regex_full_match(...)', 'regex_replace(...)', 'split(...)', 'strip(...)', 'substr(...)', 'to_hash_bucket(...)', 'to_hash_bucket_fast(...)', 'to_hash_bucket_strong(...)', 'to_number(...)', 'unicode_decode(...)', 'unicode_decode_with_offsets(...)', 'unicode_encode(...)', 'unicode_script(...)', 'unicode_split(...)', 'unicode_split_with_offsets(...)', 'unicode_transcode(...)', 'unsorted_segment_join(...)', 'upper(...)']\n",
      "[' Converts each entry in the given tensor to strings.', ' Split string elements of input into bytes.', ' Formats a string template using a list of tensors.', ' Perform element-wise concatenation of a list of string tensors.', ' String lengths of input.', ' Converts all uppercase characters into their respective lowercase replacements.', ' Create a tensor of n-grams based on data.', ' Joins all strings into a single string, or joins along an axis.', ' Check if the input matches the regex pattern.', ' Replace elements of input matching regex pattern with rewrite.', ' Split elements of input based on sep into a RaggedTensor.', ' Strip leading and trailing whitespaces from the Tensor.', ' Return substrings from Tensor of strings.', ' Converts each string in the input Tensor to its hash mod by a number of buckets.', ' Converts each string in the input Tensor to its hash mod by a number of buckets.', ' Converts each string in the input Tensor to its hash mod by a number of buckets.', ' Converts each string in the input Tensor to the specified numeric type.', ' Decodes each string in input into a sequence of Unicode code points.', ' Decodes each string into a sequence of code points with start offsets.', ' Encodes each sequence of Unicode code points in input into a string.', ' Determine the script codes of a given tensor of Unicode integer code points.', ' Splits each string in input into a sequence of Unicode code points.', ' Splits each string into a sequence of code points with start offsets.', ' Transcode the input text from a source encoding to a destination encoding.', ' Joins the elements of inputs based on segment_ids.', ' Converts all lowercase characters into their respective uppercase replacements.']\n",
      "205.xlsx\n",
      "['Example usage with tf.function graph execution', 'experimental module', 'class SummaryWriter', 'audio(...)', 'create_file_writer(...)', 'create_noop_writer(...)', 'flush(...)', 'graph(...)', 'histogram(...)', 'image(...)', 'record_if(...)', 'scalar(...)', 'should_record_summaries(...)', 'text(...)', 'trace_export(...)', 'trace_off(...)', 'trace_on(...)', 'write(...)']\n",
      "['', ' Public API for tf.summary.experimental namespace.', ' Interface representing a stateful summary writer object.', ' Write an audio summary.', ' Creates a summary file writer for the given log directory.', ' Returns a summary writer that does nothing.', ' Forces summary writer to send any buffered data to storage.', ' Writes a TensorFlow graph summary.', ' Write a histogram summary.', ' Write an image summary.', ' Sets summary recording on or off per the provided boolean value.', ' Write a scalar summary.', ' Returns boolean Tensor which is True if summaries will be recorded.', ' Write a text summary.', ' Stops and exports the active trace as a Summary and/or profile file.', ' Stops the current trace and discards any collected information.', ' Starts a trace to record computation graphs and profiling information.', ' Writes a generic summary to the default SummaryWriter if one exists.']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206.xlsx\n",
      "['get_build_info(...)', 'get_compile_flags(...)', 'get_include(...)', 'get_lib(...)', 'get_link_flags(...)']\n",
      "[\" Get a dictionary describing TensorFlow's build environment.\", ' Get the compilation flags for custom operators.', ' Get the directory containing the TensorFlow C++ header files.', ' Get the directory containing the TensorFlow framework library.', ' Get the link flags for custom operators.']\n",
      "207.xlsx\n",
      "['class Benchmark', 'class TestCase', 'assert_equal_graph_def(...)', 'benchmark_config(...)', 'compute_gradient(...)', 'create_local_cluster(...)', 'disable_with_predicate(...)', 'gpu_device_name(...)', 'is_built_with_cuda(...)', 'is_built_with_gpu_support(...)', 'is_built_with_rocm(...)', 'is_built_with_xla(...)', 'is_gpu_available(...)', 'main(...)']\n",
      "[' Abstract class that provides helpers for TensorFlow benchmarks.', ' Base class for tests that need to test TensorFlow.', ' Asserts that two GraphDefs are (mostly) the same.', ' Returns a tf.compat.v1.ConfigProto for disabling the dependency optimizer.', ' Computes the theoretical and numeric Jacobian of f.', ' Create and start local servers and return the associated Server objects.', ' Disables the test if pred is true.', ' Returns the name of a GPU device if available or a empty string.', ' Returns whether TensorFlow was built with CUDA (GPU) support.', ' Returns whether TensorFlow was built with GPU (CUDA or ROCm) support.', ' Returns whether TensorFlow was built with ROCm (GPU) support.', ' Returns whether TensorFlow was built with XLA support.', ' Returns whether TensorFlow can access a GPU. (deprecated)', ' Runs all unit tests.']\n",
      "208.xlsx\n",
      "['experimental module', 'class XLAOptions']\n",
      "[' Public API for tf.tpu.experimental namespace.', ' XLA compilation options.']\n",
      "209.xlsx\n",
      "['experimental module', 'class BytesList', 'class BytesList', 'class Checkpoint', 'class CheckpointManager', 'class CheckpointOptions', 'class ClusterDef', 'class ClusterSpec', 'class Coordinator', 'class Example', 'class ExponentialMovingAverage', 'class Feature', 'class FeatureList', 'class FeatureList', 'class FeatureLists', 'class FeatureLists', 'class Features', 'class Features', 'class FloatList', 'class FloatList', 'class Int64List', 'class Int64List', 'class JobDef', 'class SequenceExample', 'class ServerDef', 'checkpoints_iterator(...)', 'get_checkpoint_state(...)', 'latest_checkpoint(...)', 'list_variables(...)', 'load_checkpoint(...)', 'load_variable(...)']\n",
      "[' Public API for tf.train.experimental namespace.', ' Container that holds repeated fundamental values of byte type in the tf.train.Feature message.', ' Container that holds repeated fundamental values of byte type in the tf.train.Feature message.', ' Manages saving/restoring trackable values to disk.', ' Manages multiple checkpoints by keeping some and deleting unneeded ones.', ' Options for constructing a Checkpoint.', ' A ProtocolMessage', ' Represents a cluster as a set of \"tasks\", organized into \"jobs\".', ' A coordinator for threads.', ' An Example is a mostly-normalized data format for storing data for training and inference.', ' Maintains moving averages of variables by employing an exponential decay.', ' A Feature is a list which may hold zero or more values.', ' Contains zero or more values of tf.train.Features.', ' Contains zero or more values of tf.train.Features.', ' Contains the mapping from name to tf.train.FeatureList.', ' Contains the mapping from name to tf.train.FeatureList.', ' Protocol message for describing the features of a tf.train.Example.', ' Protocol message for describing the features of a tf.train.Example.', ' Container that holds repeated fundamental values of float type in the tf.train.Feature message.', ' Container that holds repeated fundamental values of float type in the tf.train.Feature message.', ' Container that holds repeated fundamental value of int64 type in the tf.train.Feature message.', ' Container that holds repeated fundamental value of int64 type in the tf.train.Feature message.', ' A ProtocolMessage', ' A SequenceExample is a format for representing one or more sequences and some context.', ' A ProtocolMessage', ' Continuously yield new checkpoint files as they appear.', ' Returns CheckpointState proto from the \"checkpoint\" file.', ' Finds the filename of latest saved checkpoint file.', ' Lists the checkpoint keys and shapes of variables in a checkpoint.', ' Returns CheckpointReader for checkpoint found in ckpt_dir_or_file.', ' Returns the tensor value of the given variable in the checkpoint.']\n",
      "210.xlsx\n",
      "['experimental module']\n",
      "[' Public API for tf.types.experimental namespace.']\n",
      "211.xlsx\n",
      "[]\n",
      "[]\n",
      "212.xlsx\n",
      "['experimental module']\n",
      "[' Public API for tf.xla.experimental namespace.']\n"
     ]
    }
   ],
   "source": [
    "n = 200 # starting excel file number\n",
    "for html_doc in Links:\n",
    "    doc = requests.get('https://www.tensorflow.org/api_docs/python/tf/'+html_doc)\n",
    "    src = doc.content;\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "    fun = []\n",
    "    desc = []\n",
    "    s = soup.find_all('code')\n",
    "    for i in s:\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            st = i.parent.parent.getText()\n",
    "            f, d = st.split(':')\n",
    "            fun.append(f)\n",
    "            desc.append(d)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    name = str(n)+'.xlsx'\n",
    "    excel_write(name, fun, desc)\n",
    "    n += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all the excel files into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading all the excel files and creating single file\n",
    "import openpyxl\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'files/1.xlsx'\n",
    "wb_obj = openpyxl.load_workbook(path)\n",
    "\n",
    "sheet_obj = wb_obj.active\n",
    "\n",
    "cell_obj = sheet_obj.cell(row = 1, column = 2)\n",
    " \n",
    "# Print value of cell object\n",
    "# using the value attribute\n",
    "print(cell_obj.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'Out.xlsx'\n",
    "n = 0\n",
    "fun = []\n",
    "desc = []\n",
    "for i in range(1,136):\n",
    "    file = 'files/'+str(i)+'.xlsx'\n",
    "    # open file\n",
    "    wb_obj = openpyxl.load_workbook(file)\n",
    "    sheet_obj = wb_obj.active\n",
    "    #print(sheet_obj.max_row)\n",
    "    #cell_obj = sheet_obj.cell(row=1, column=2)\n",
    "\n",
    "    for j in range(sheet_obj.max_row):\n",
    "        if sheet_obj['B'+str(j+1)].value is not None:\n",
    "            fun.append(sheet_obj['A'+str(j+1)].value)\n",
    "            desc.append(sheet_obj['B'+str(j+1)].value)\n",
    "       \n",
    "# write to the file\n",
    "excel_write_all(outfile, fun, desc, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
